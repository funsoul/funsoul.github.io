---
title: 笔记：概论(1)--李航《统计学习方法》
date: 2019-12-08
categories:
  - 技术
tags: 
  - 机器学习
  - 笔记
  - 统计学习方法
---

![概论](/images/读书笔记/统计学习方法/概论.png)

统计学习是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也称为统计机器学习。

赫伯特·西蒙：“如果一个系统能够通过执行某个过程改进它的性能，这就是学习。”。还说过，“系统为了适应环境而形成的一种长久的变化，这种变化使得系统更有成效地完成下一次同类的工作”。

对象是数据（数字、文字、图像、视频、音频以及它们的组合），从数据从发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中。

目的是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。

方法有监督学习、非监督学习、半监督学习和强化学习。其中，监督学习可以概括为：从给定的、有限的、用于学习的训练数据集合出发，假设数据是``独立同分布``产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间(hypothesis space)；应用某个评价准则(evaluation criterion)，从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现，这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法，称其为统计学习的方法的三要素：模型、策略和算法。

>独立同分布：是指一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立。一组随机变量独立同分布并不意味着它们的样本空间中每个事件发生概率都相同。例如，投掷非均匀骰子得到的结果序列是独立同分布的，但掷出每个面朝上的概率并不相同。—— 来自维基百科

实现统计学习方法的步骤
1. 得到一个有限的训练数据集合；
2. 确定包含所有可能的模型的假设空间，即学习模型的集合；
3. 确定模型选择的准则，即学习的策略；
4. 实现求解最优模型的算法，即学习的算法；
5. 通过学习方法选择最优模型；
6. 利用学习的最优模型对新数据进行预测和分析

监督学习方法主要包括用于``分类``、``标注``和``回归``问题的方法。这些方法在自然语言处理、信息检索、文本数据挖掘等领域有着极其广泛的应用。

在监督学习中，将输入与输出所有可能取值的集合分别称为输入空间和输出空间。输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。输入空间与输出空间可以是同一个空间，也可以是不同的空间，但通常输出空间远远小于输入空间。

>欧氏空间：欧几里得几何是在约公元前300年，由古希腊数学家欧几里得建立的角和空间中距离之间联系的法则。欧几里得首先开发了处理平面上二维物体的“平面几何”，他接着分析三维物体的“立体几何”，所有欧几里得的公理被编排到几何原本。这些数学空间可以被扩展来应用于任何有限维度，而这种空间叫做n维欧几里得空间（甚至简称n维空间）或有限维实内积空间。这些数学空间还可被扩展到任意维的情形，称为实内积空间（不一定完备），希尔伯特空间在高等代数教科书中也被称为欧几里得空间。为了开发更高维的欧几里得空间，空间的性质必须非常仔细的表达并被扩展到任意维度。尽管结果的数学非常抽象，它却呈现了我们熟悉的欧几里得空间的根本本质 —— 平面性。 另外也存在其他种类的空间，例如球面非欧几里得空间，相对论所描述的四维时空在重力出现的时候也不是欧几里得空间。

监督学习从训练数据集合中学习模型，对测试数据进行预测。训练数据由输入（或特征向量）与输出对组成，训练集通常表示为：

T = {(x1, y1), (x2, y2),..,(xn, yn)}

测试数据也由相应的输入与输出对组成，输入与输出对又称为样本（sample）或者样本点。

输入变量X与输出变量Y有不同的类型，可以是连续的，也可以是离散的。人们根据输入、输出变量的不同类型，对预测任务给予不同的名词：

- 回归问题：输入变量与输出变量均为连续变量的预测问题
- 分类问题：输出变量为有限个离散变量的预测问题
- 标注问题：输入变量与输出变量均为变量序列的预测问题

监督学习假设输入与输出的随机变量X和Y遵循``联合概率分布P(X, Y)``

监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到最好的这样的模型。模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间（hypothesis space）。假设空间的确定意味着学习范围的确定。

监督学习的模型可以是概率模型或非概率模型，由``条件概率分布P(Y|X)``或``决策函数(decision function)Y=f(X)``表示，随具体学习方法而定。对具体的输入进行相应的输出预测时，写作P(y|x)或y=f(x).

三要素：方法 = 模型 + 策略 + 算法

损失函数度量模型一次预测的好坏，风险函数（期望损失）度量平均意义下模型预测的好坏。

对于给定的输入X，由f(X)给出相应的输出Y，这个输出的预测值f(X)与真实值可能一致也可能不一致，用一个损失函数（loss function）或代价函数（cost function）来度量预测错误的程度。损失函数是f(X)与Y的``非负实值函数``，记作L(Y, f(X))

常用损失函数：
1. 0-1损失函数（0-1 loss function）
2. 平方损失函数（quadratic loss function）
3. 绝对损失函数（absolute loss function）
4. 对数损失函数（logarithmic loss function）或对数似然损失函数（likelihood loss function）

损失函数值越小，模型就越好。学习的目标就是选择期望风险最小的模型。由于联合分布P(X, Y)是未知的，损失函数的期望不能直接计算。实际上，如果知道联合分布P(X, Y)，可以从联合分布直接求出条件概率分布P(Y|X)，也就不需要学习了。正因为不知道联合概率分布，所以才需要学习。这样一来，一方面根据期望风险最小学习模型要用到联合分布，另一方面联合分布又是未知的，所以监督学习就成为一个病态问题（ill-formed problem）

